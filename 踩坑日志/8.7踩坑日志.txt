1.所有的sh脚本如果在windows平台编写，一定要把右下方的编写平台改为unix，否则换行符会是/r/n，linux会额外读取一个/r。
直接导致sqoop语句的续航操作失败。

2.sqoop 参数中的-- import 参数跟其他参数不一样，需要前后都空一格

3.我的hive2.3版本不知道为什么打印到控制台的信息量有点少，但是输出的信息量还算能接受，为了以后使用spark引擎着想，这个项目开始我将使用原生hadoop2.7+hive2.3的版本